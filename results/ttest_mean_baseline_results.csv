Activation Function \ Learning Rate,.001,.0001,.00001
Tanh,-13.288680725671476,13.328062461186482,-11.288680725671476
Sigmoid,-2.3100754672170427,17.67648618433472,-0.3100754672170427
ReLU,-8.436574085355234,28.962178398863664,-6.436574085355234
