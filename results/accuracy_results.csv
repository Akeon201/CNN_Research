Activation Function \ Learning Rate,.001,.0001,.00001
Tanh,0.3254666666666665,0.4004999999999999,0.3210666666666666
Sigmoid,0.3575666666666667,0.40869999999999995,0.3028666666666667
ReLU,0.3393666666666666,0.44456666666666655,0.3762
